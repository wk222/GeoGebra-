import { ChatOpenAI } from '@langchain/openai';
import { ChatAnthropic } from '@langchain/anthropic';
import { Agent, AgentConfig, ChatResponse } from '../types/agent';
import { Message } from '../types';
import logger from '../utils/logger';

/**
 * ç»ƒä¹ é¢˜ç”Ÿæˆå™¨æ™ºèƒ½ä½“ï¼ˆçº¯æ–‡æœ¬ç‰ˆæœ¬ï¼‰
 */
export class ExerciseGeneratorAgent extends Agent {
  private model: any;
  private currentAIConfig: any;

  constructor() {
    const config: AgentConfig = {
      id: 'exercise-generator',
      name: 'ç»ƒä¹ é¢˜ç”Ÿæˆå™¨',
      description: 'ä¸“é•¿ï¼šæ ¹æ®çŸ¥è¯†ç‚¹ç”Ÿæˆåˆ†çº§ä¹ é¢˜ï¼ŒåŒ…å«ç­”æ¡ˆå’Œè¯¦ç»†è§£æã€‚æ”¯æŒé€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜ã€è§£ç­”é¢˜ã€‚',
      icon: 'ğŸ“',
      systemPrompt: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°å­¦ä¹ é¢˜ç”Ÿæˆä¸“å®¶ï¼Œæ“…é•¿æ ¹æ®çŸ¥è¯†ç‚¹åˆ›å»ºé«˜è´¨é‡çš„ç»ƒä¹ é¢˜ã€‚

ä½ çš„ä»»åŠ¡ï¼š
1. ç†è§£ç”¨æˆ·æŒ‡å®šçš„æ•°å­¦çŸ¥è¯†ç‚¹æˆ–ç« èŠ‚
2. ç”Ÿæˆé€‚åˆåˆé«˜ä¸­éš¾åº¦çš„ç»ƒä¹ é¢˜
3. æä¾›å®Œæ•´çš„ç­”æ¡ˆå’Œè¯¦ç»†è§£æ
4. æ ¹æ®éœ€æ±‚è°ƒæ•´é¢˜ç›®éš¾åº¦

è¾“å‡ºæ ¼å¼ï¼ˆä½¿ç”¨ Markdown + LaTeXï¼‰ï¼š

## ğŸ“‹ ç»ƒä¹ é¢˜é›† - [çŸ¥è¯†ç‚¹åç§°]

### éš¾åº¦ï¼šâ­ ç®€å• / â­â­ ä¸­ç­‰ / â­â­â­ å›°éš¾

---

### é¢˜ç›® 1ï¼š[é¢˜å‹]

**é—®é¢˜ï¼š**
[é¢˜ç›®æè¿°]

**é€‰é¡¹ï¼š**ï¼ˆå¦‚æœæ˜¯é€‰æ‹©é¢˜ï¼‰
A. [é€‰é¡¹A]
B. [é€‰é¡¹B]
C. [é€‰é¡¹C]
D. [é€‰é¡¹D]

<details>
<summary>ğŸ’¡ ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

**ç­”æ¡ˆï¼š** [æ­£ç¡®ç­”æ¡ˆ]

**è¯¦ç»†è§£æï¼š**
1. [è§£é¢˜æ€è·¯ç¬¬ä¸€æ­¥]
2. [è§£é¢˜æ€è·¯ç¬¬äºŒæ­¥]
3. [è§£é¢˜æ€è·¯ç¬¬ä¸‰æ­¥]

**çŸ¥è¯†ç‚¹ï¼š** [æ¶‰åŠçš„çŸ¥è¯†ç‚¹]

**æ˜“é”™ç‚¹ï¼š** [å¸¸è§é”™è¯¯åŠåŸå› ]

</details>

---

## LaTeX æ•°å­¦å…¬å¼è§„èŒƒï¼š

- è¡Œå†…å…¬å¼ä½¿ç”¨ $...$ 
- ç‹¬ç«‹å…¬å¼ä½¿ç”¨ $$...$$ 
- ç¤ºä¾‹ï¼š
  - è¡Œå†…ï¼šå‡½æ•° $f(x) = x^2 + 2x + 1$
  - ç‹¬ç«‹ï¼š$$f(x) = ax^2 + bx + c$$

ä½¿ç”¨ä¸­æ–‡ï¼Œè¯­è¨€æ¸…æ™°ï¼Œé¢˜ç›®è¦æœ‰æ•™å­¦ä»·å€¼ï¼Œè§£æè¦è¯¦ç»†æ˜“æ‡‚ã€‚`,
      tools: [],
      enabled: true,
    };
    super(config);
  }

  getTools() {
    return [];
  }

  private createModelInstance(aiConfig: any) {
    const { provider, model, apiKey, baseURL } = aiConfig;

    if (provider === 'openai' || provider === 'custom') {
      return new ChatOpenAI({
        model: model || 'gpt-4-turbo-preview',
        apiKey: apiKey,
        configuration: {
          baseURL: baseURL,
        },
        temperature: 0.7,
      });
    } else if (provider === 'anthropic') {
      return new ChatAnthropic({
        model: model || 'claude-3-5-sonnet-20241022',
        apiKey: apiKey,
        temperature: 0.7,
      });
    }

    return new ChatOpenAI({
      model: model || 'gpt-4-turbo-preview',
      apiKey: apiKey,
      configuration: {
        baseURL: baseURL,
      },
      temperature: 0.7,
    });
  }

  async chat(messages: Message[], aiConfig: any): Promise<ChatResponse> {
    if (!this.model || JSON.stringify(this.currentAIConfig) !== JSON.stringify(aiConfig)) {
      this.model = this.createModelInstance(aiConfig);
      this.currentAIConfig = aiConfig;
    }

    try {
      const conversationMessages = [
        { role: 'system', content: this.config.systemPrompt },
        ...messages.map(msg => ({
          role: msg.role,
          content: msg.content,
        })),
      ];

      logger.info(`ğŸ“ ç»ƒä¹ é¢˜ç”Ÿæˆå™¨æ™ºèƒ½ä½“å¼€å§‹å¤„ç†...`);

      const response = await this.model.invoke(conversationMessages);

      const assistantMessage: Message = {
        id: `msg_${Date.now()}`,
        role: 'assistant',
        content: response.content,
        timestamp: new Date(),
      };

      logger.info(`âœ… ç»ƒä¹ é¢˜ç”Ÿæˆå®Œæˆ`);

      return {
        message: assistantMessage,
        toolCalls: [],
      };
    } catch (error) {
      logger.error('âŒ ç»ƒä¹ é¢˜ç”Ÿæˆå™¨æ™ºèƒ½ä½“å¤„ç†å¤±è´¥', error);
      throw error;
    }
  }
}
